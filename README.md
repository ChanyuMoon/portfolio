## Chanyu Moon | 문찬유
### About me
I am master student in DGIST, advised by professor [Ji-Woong Choi](https://scholar.google.com/citations?user=V2I9oYMAAAAJ&hl=ko).  
I received by Bachelor's degree in Computer Science and Electronic Engineering from DGIST in 2024.  
Check out my cv / [github](https://github.com/ChanyuMoon) / [scholar](https://scholar.google.com/citations?hl=ko&user=l9m2FnQAAAAJ&view_op=list_works&gmla=AOv-ny9DsJGv4hvrmkwzkQ1cEgpMwCDR970UmxZ3N7SV3a4Dlm_iVlBUXitqVo5yJLbwvRNc-Mauupg--xHyhdqGDeWMOyOZKwUoq1-PnUErZTnulV4-h1cMdQ)  
### Research
I am interested in the brain. I want to understand how our brain performs cognitive functions and motor control, and why patients with brain disorders such as Parkinson's disease experience certain symptoms.  
\* states the Equal Contribution  

**OFF-CLIP: Improving Normal Detection Confidence in Radiology CLIP with Simple Off-Diagonal Term Auto-Adjustment**  
Junhyun Park\*, **Chanyu Moon\***, Donghwan Lee, Kyungsu Kim, Minho Hwang  
arXiv, 2025  
[arXiv](https://arxiv.org/pdf/2503.01794)  
![image](assets/img/1_offclip_figure.png)  
<div style="font-size:13px; margin:0;">
    Contrastive Language-Image Pre-Training (CLIP) has enabled zero-shot classification in radiology. However, conventional contrastive learning struggles with normal case detection due to its strict intra-sample alignment. To address this, we propose OFF-CLIP, a contrastive learning refinement that improves normal detection by introducing an off-diagonal term loss to enhance normal sample clustering and by implementing sentence-level text filtering to mitigate false negatives by removing misaligned normal statements from abnormal reports. Additionally, OFF-CLIP can be applied to radiology CLIP models without requiring any architectural modifications. Compared to the current state-of-the-art model, CARZero, OFF-CLIP significantly improves normal classification (0.61 AUC increase on VinDr-CXR). Furthermore, our model enhances zero-shot grounding by improving pointing game accuracy.
</div>
